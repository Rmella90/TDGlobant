{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OSError while attempting to symlink the latest log directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">C:\\Users\\REMO\\AppData\\Local\\Temp\\ipykernel_2480\\</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4028859749.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">7</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.operators.python_operator.PythonOperator` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.operators.python.PythonOperator'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mC:\\Users\\REMO\\AppData\\Local\\Temp\\ipykernel_2480\\\u001b[0m\u001b[1;33m4028859749.\u001b[0m\u001b[1;33mpy:\u001b[0m\u001b[1;33m7\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.operators.python_operator.PythonOperator` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.operators.python.PythonOperator'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "from pandas_gbq import to_gbq\n",
    "import pandas_gbq\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(**kwargs):\n",
    "    url = \"https://drive.google.com/uc?id=1nfktbI7ucHOUwO6EHD2pPHvOf1hN9nmZ\"\n",
    "    destination_file = \"videogame.csv\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(destination_file, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            print(f\"The file {destination_file} has been successfully downloaded.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n",
    "    df = pd.read_csv(destination_file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    dataframes = {}\n",
    "    dataframe_names = []\n",
    "\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for columna in df.columns:\n",
    "        if df[columna].isnull().any():\n",
    "            df_temp = df.dropna(subset=[columna])\n",
    "            df_temp = df_temp.dropna(axis=1, how='all')\n",
    "            df_temp = df_temp.rename(columns={columna: 'Plataforma'})\n",
    "\n",
    "            df_name = f'DF_{i}'\n",
    "            dataframes[df_name] = df_temp\n",
    "            dataframe_names.append(df_name)\n",
    "            i += 1\n",
    "\n",
    "    dataframes_list = []\n",
    "    for df_name in dataframe_names:\n",
    "        df_temp = dataframes[df_name]\n",
    "        dataframes_list.append(df_temp)\n",
    "\n",
    "    # Concatena los DataFrames de manera vertical\n",
    "    df2 = pd.concat(dataframes_list, axis=0)\n",
    "\n",
    "\n",
    "    df2[['Genero', 'Editorial']] = df2['Genero-Editorial'].str.rsplit('-', n=1, expand=True)\n",
    "    df2 = df2.drop('Genero-Editorial', axis=1)\n",
    "\n",
    "    df2['Ventas NA'] = df2['Ventas NA'].str.replace(',', '.', regex=True).astype(float)\n",
    "    df2['Ventas EU'] = df2['Ventas EU'].str.replace(',', '.', regex=True).astype(float)\n",
    "    df2['Ventas JP'] = df2[ 'Ventas JP'].str.replace(',', '.', regex=True).astype(float)\n",
    "    df2['Ventas Otros'] = df2['Ventas Otros'].str.replace(',', '.', regex=True).astype(float)\n",
    "    df2['Ventas Global'] = df2['Ventas Global'].str.replace(',', '.', regex=True).astype(float)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(df2):\n",
    "    project_id = 'globanttd'\n",
    "    dataset_id = 'Videogames'\n",
    "    table_id = 'videogames1'\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'  # Opcional: Sobrescribe la tabla existente.\n",
    "\n",
    "    # Carga el DataFrame en BigQuery.\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "    job = client.load_table_from_dataframe(df2, table_ref, location='US', job_config=job_config)\n",
    "    job.result()  # Espera a que se complete el trabajo de carga.\n",
    "\n",
    "    print(f'Datos cargados en {project_id}.{dataset_id}.{table_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): upload_data_to_bigquery>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "default_args = {\n",
    "    'owner': 'GORRO',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 10, 12),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'my_data_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Un DAG para descargar, transformar y cargar datos',\n",
    "    schedule=timedelta(minutes=10),  # Ejecutar cada 10 minutos\n",
    "    catchup=False,\n",
    ")\n",
    "\n",
    "# Crea las tareas para descargar, transformar y cargar datos\n",
    "download_task = PythonOperator(\n",
    "    task_id='download_data',\n",
    "    python_callable=download_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "transform_task = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "upload_task = PythonOperator(\n",
    "    task_id='upload_data_to_bigquery',\n",
    "    python_callable=upload_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Define el orden de ejecuciÃ³n de las tareas\n",
    "download_task >> transform_task >> upload_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\REMO\\Desktop\\Analisis de Datos\\Poyecto Procesamiento\\TDGlobant\\aumatized_with_apache.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/REMO/Desktop/Analisis%20de%20Datos/Poyecto%20Procesamiento/TDGlobant/aumatized_with_apache.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df2\u001b[39m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
