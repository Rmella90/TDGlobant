# TDGlobant
GLOBANT INTERNSHIP PROGRAM - DIGITAL TALENT FOR CHILE 2023
Develop a small ETL process that collects data from a source, transforms it, and then upload them to BigQuery. During this process, agile methodology was applied using a jira board.

https://rmella.atlassian.net/jira/software/projects/GP/boards/2


The project was divided into 11 sprints documented on the jira board. (It's my first time using Jira, the task scheduler, and connecting a python programming environment to bigquery, it was a great challenge). In this repository you will find This Readme. A final notebook called 'aumatized_with_cronojobs', a credential with bigquery json format to load the data. the csv file that downloads from drive with the dowload function code. and an initial file where the initial codes were generated to explore and modify the database, and it is from where the code is finally extracted to generate the simplified functions.


To do this we need to have the libraries installed:

pandas
pyarrow
google-cloud-bigquery
pandas-gbq
apache-airflow (An attempt was made to generate data ingestion with Apache, but finally it was done with the Windows task scheduler)
import requests
sqlalchemy
datetime 
google.cloud
google.oauth2
